<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>News &amp; Posts | Vision and Learning Lab @ UAlberta</title>
    <link>https://vision-and-learning-lab-ualberta.github.io/post/</link>
      <atom:link href="https://vision-and-learning-lab-ualberta.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <description>News &amp; Posts</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© Vision and Learning Lab, Univerity of Alberta 2025</copyright><lastBuildDate>Mon, 01 Sep 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://vision-and-learning-lab-ualberta.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>News &amp; Posts</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/</link>
    </image>
    
    <item>
      <title>Welcome Jiahui, who recently joined in our lab as a MSc student.</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/jiahui_newstudent_2025/</link>
      <pubDate>Mon, 01 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/jiahui_newstudent_2025/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Welcome Dr. Pengyu Zhang, who recently joined in our lab as a Postdoc Fellow.</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/pengyu_newpostdoc_2025/</link>
      <pubDate>Wed, 26 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/pengyu_newpostdoc_2025/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Congrats to Hang Zhou for having two papers being accepted into CVPR 2025!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/hang_cvpr_2025/</link>
      <pubDate>Wed, 26 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/hang_cvpr_2025/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Congrats to Jun for his paper, Hand Gesture Recognition from an Open-Set Perspective, being accepted recently by IEEE TMM!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/jun_tmm_2025/</link>
      <pubDate>Fri, 24 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/jun_tmm_2025/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Two papers in our lab are accepted into ICLR 2025. They are 1st authored by Yilin and Gohar, respectively. Congratulations!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/2025_iclr/</link>
      <pubDate>Wed, 22 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/2025_iclr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Welcome Dr. Jing Wang, who recently joined in our lab as a Postdoc Fellow.</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/jingwang_newpostdoc_2025/</link>
      <pubDate>Wed, 15 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/jingwang_newpostdoc_2025/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Congratulates to Gohar for successfully passing his MSc Exam! We wish him all the best in his future endeavors.</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/gohar_defense_2024/</link>
      <pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/gohar_defense_2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Welcome Dr. Hang Zhou, who recently joined in our lab as a Postdoc Fellow.</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/hang_newpostdoc_2024/</link>
      <pubDate>Fri, 04 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/hang_newpostdoc_2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Welcome Jun Zhou, who recently joined in our lab as a visiting PhD student.</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/junzhou_visitingstudent_2024/</link>
      <pubDate>Fri, 04 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/junzhou_visitingstudent_2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;Unleashing Multispectral Video&#39;s Potential in Semantic Segmentation: A Semi-supervised Viewpoint and New UAV-View Benchmark&#34; is accepted by NeurIPS 2024.</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/wei_neurips2024/</link>
      <pubDate>Wed, 25 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/wei_neurips2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Welcome Akash Ghimire, who recently joined in our lab as a MSc student.</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/akash_newstudent_2024/</link>
      <pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/akash_newstudent_2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;RegionGrasp: A Novel Task for Contact Region Controllable Hand Grasp Generation&#34; is accepted by European Conference on Computer Vision (ECCV) Workshop HANDS@ECCV2024!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/yilin_eccvw_2024/</link>
      <pubDate>Tue, 20 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/yilin_eccvw_2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Congratulates to Yuxuan for successfully passing his MSc Exam! We wish him all the best in his future endeavors.</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/yuxuan_defense_2024/</link>
      <pubDate>Tue, 13 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/yuxuan_defense_2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;GSD: View-Guided Gaussian Splatting Diffusion for 3D Reconstruction&#34; is accepted by European Conference on Computer Vision (ECCV) 2024!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/yuxuan_eccv_2024/</link>
      <pubDate>Tue, 13 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/yuxuan_eccv_2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;RACon: Retrieval-Augmented Simulated Character Locomotion Control &#34; is accepted by IEEE International Conference on Multimedia &amp; Expo (ICME) 2024 for oral presentation!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/yuxuan_icme_2024/</link>
      <pubDate>Mon, 12 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/yuxuan_icme_2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Welcome Hamid Mohammadi, who recently joined in our lab as a Ph.D. student.</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/hamid_newphd_2024/</link>
      <pubDate>Tue, 02 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/hamid_newphd_2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Akash has been awarded the Stanley G. Jones Master&#39;s Scholarship in Applied Electrical and Computer Engineering. Congratulations!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/akash_stanley_2024/</link>
      <pubDate>Wed, 26 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/akash_stanley_2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Jingjing has been awarded the Andrew Stewart Memorial Graduate Prize. Congratulations!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/jingjing_andrew_2024/</link>
      <pubDate>Wed, 26 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/jingjing_andrew_2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Congratulates to Dr. Wei Ji for successfully defending his PhD thesis! We wish him continued success and innovation in his future endeavors.</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/wei_defense_2024/</link>
      <pubDate>Mon, 22 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/wei_defense_2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;MoMask: Generative Masked Modeling of 3D Human Motions &#34; is accepted by IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2024!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/chuan_cvpr_2024/</link>
      <pubDate>Tue, 27 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/chuan_cvpr_2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Congratulates to Dr. Chuan Guo for successfully defending his PhD thesis! We wish him all the best in his future endeavors and are confident that his work will continue to inspire and lead to significant advancements.</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/chuan_defense_2024/</link>
      <pubDate>Fri, 19 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/chuan_defense_2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;Generative Human Motion Stylization in Latent Space &#34; is accepted by International Conference on Learning Representations (ICLR) 2024!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/chuan_iclr_2024/</link>
      <pubDate>Tue, 16 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/chuan_iclr_2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Congratulates to Jingjing for being awarded the Alberta Innovate Graduate Scholarship!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/jingjing_aigsscholarship_2023/</link>
      <pubDate>Fri, 08 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/jingjing_aigsscholarship_2023/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Congratulates to Dr. Shihao Zou for successfully defending his PhD thesis! We wish him continued success and innovation in his future endeavors.</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/shihao_defense_2023/</link>
      <pubDate>Wed, 06 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/shihao_defense_2023/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Welcome Dr. Yande Li, who recently joined in our lab as a Postdoc Fellow.</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/yande_newpostdoc_2023/</link>
      <pubDate>Wed, 22 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/yande_newpostdoc_2023/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Congratulates to Yuxuan for being awarded the Alberta Graduate Excellence Scholarship!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/yuxuan_agesschsp_2023/</link>
      <pubDate>Thu, 09 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/yuxuan_agesschsp_2023/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Congratulates to Jingjing for being awarded the Floyd Derkat Graduate Award in Artificial Intelligence and Machine Learning!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/jingjing_fgdawards_2023/</link>
      <pubDate>Fri, 25 Aug 2023 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/jingjing_fgdawards_2023/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our CVPR 2023 workshop paper &#34;Segment Anything Is Not Always Perfect: An Investigation of SAM on Different Real-world Applications&#34; has won the most insightful paper award presented by the 1st Workshop on Vision-based InduStrial InspectiON!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/wei_cvprws_2023/</link>
      <pubDate>Fri, 28 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/wei_cvprws_2023/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;Multispectral Video Semantic Segmentation: A Benchmark Dataset and Baseline&#34; is accepted by IEEE Conference on Computer Vision and Pattern Recognition 2023!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/wei_cvpr_2023/</link>
      <pubDate>Tue, 28 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/wei_cvpr_2023/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Congratulates to Wei for being awarded the Alberta Innovate Graduate Scholarship!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/wei_aigsscholarship_2022/</link>
      <pubDate>Fri, 24 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/wei_aigsscholarship_2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Congratulates to Chuan for being awarded the Alberta Innovate Graduate Scholarship!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/chuan_aigsscholarship_2022/</link>
      <pubDate>Mon, 13 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/chuan_aigsscholarship_2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;Delving into Calibrated Depth for Accurate RGB-D Salient Object Detection&#34; is accepted by Interactional Journal of Computer Vision (IJCV) 2023!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/jingjing_ijcv2023/</link>
      <pubDate>Fri, 09 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/jingjing_ijcv2023/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Congratulates to Jingjing for being awarded the Alberta Graduate Excellence Scholarship!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/jignjing_agescholarship_2022/</link>
      <pubDate>Thu, 17 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/jignjing_agescholarship_2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Congratulates to Wei on being awarded the Floyd Derkat Graduate Award in Artificial Intelligence and Machine Learning!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/wei_fgdawards_2022/</link>
      <pubDate>Thu, 17 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/wei_fgdawards_2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;Object Wake-up: 3D Object Rigging from a Single Image&#34; is accepted by European Conference on Computer Vision (ECCV) 2022!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/ji_eccv_2022/</link>
      <pubDate>Fri, 15 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/ji_eccv_2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;TM2T: Stochastic and Tokenized Modeling for the Reciprocal Generation of 3D Human Motions and Texts.&#34; is accepted by European Conference on Computer Vision (ECCV) 2022!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/chuan_eccv_2022/</link>
      <pubDate>Fri, 15 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/chuan_eccv_2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;Contrastive Learning for Unsupervised Video Highlight Detection&#34; is accepted by IEEE Conference on Computer Vision and Pattern Recognition(CVPR) 2022!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/tk_cvpr_2022/</link>
      <pubDate>Mon, 07 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/tk_cvpr_2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;Exploring Denoised Cross-video Contrast for Weakly-supervised Temporal Action Localization&#34; is accepted by IEEE Conference on Computer Vision and Pattern Recognition(CVPR) 2022!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/jingjing_cvpr_2022/</link>
      <pubDate>Mon, 07 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/jingjing_cvpr_2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;Generating Diverse and Natural 3D Human Motions from Text&#34; is accepted by IEEE Conference on Computer Vision and Pattern Recognition(CVPR) 2022!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/chuan_cvpr_2022/</link>
      <pubDate>Mon, 07 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/chuan_cvpr_2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;Action2video: Generating Videos of Human 3D Actions&#34; is accepted by International Journal of Computer Vision(IJCV) 2022!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/chuan_ijcv_2022/</link>
      <pubDate>Tue, 04 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/chuan_ijcv_2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;Investigating Pose Representations and Motion Contexts Modeling for 3D Motion Prediction&#34; is accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)!</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/shuang_tpami2022/</link>
      <pubDate>Tue, 04 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/shuang_tpami2022/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;Joint Semantic Mining for Weakly Supervised RGB-D Salient Object Detection&#34; is accepted by NeurIPS 2021</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/jingjing_neurips2021/</link>
      <pubDate>Mon, 06 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/jingjing_neurips2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;3D pose estimation and future motion prediction from 2D images&#34; is accepted by Pattern Recogntion</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/ji_pr_2021/</link>
      <pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/ji_pr_2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;CHASE: Robust Visual Tracking via Cell-Level Differentiable Neural Architecture Search&#34; is accepted by BMVC 2021</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/mojtaba_bmvc2021/</link>
      <pubDate>Sun, 26 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/mojtaba_bmvc2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;Enhancing Human Motion Assessment by Self-supervised Representation Learning&#34; is accepted by BMVC 2021</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/mahdiar_bmvc2021/</link>
      <pubDate>Sun, 26 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/mahdiar_bmvc2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;Automated Generation of Accurate &amp; Fluent Medical X-ray Reports&#34; is accepted by EMNLP 2021</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/hoang_emnlp2021/</link>
      <pubDate>Fri, 27 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/hoang_emnlp2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;Dual Learning Music Composition and Dance Choreography&#34; is accepted by ACM Multimedia 2021</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/shuang_acmmm2021/</link>
      <pubDate>Mon, 26 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/shuang_acmmm2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;EventHPE: Event-based 3-D Human Pose Estimation&#34; is accepted by ICCV 2021</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/shihao_iccv2021/</link>
      <pubDate>Mon, 26 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/shihao_iccv2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;Joint Visual and Audio Learning for Video Highlight Detection&#34; is accepted by ICCV 2021</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/tk_iccv2021/</link>
      <pubDate>Mon, 26 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/tk_iccv2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;Calibrated RGB-D Salient Object Detection&#34; is accepted by IEEE Conference on Computer Vision and Pattern Recognition 2021</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/wei_cvpr_2021a/</link>
      <pubDate>Tue, 16 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/wei_cvpr_2021a/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;Learning Calibrated Medical Image Segmentation via Multi-rater Agreement Modeling&#34; is accepted by IEEE Conference on Computer Vision and Pattern Recognition 2021 (Best Paper Candidate)</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/wei_cvpr_2021b/</link>
      <pubDate>Tue, 16 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/wei_cvpr_2021b/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;Deep Learning for Visual Tracking: A Comprehensive Survey&#34; is accepted by IEEE Transactions on Intelligent Transportation Systems (T-ITS)</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/mojtaba_tits2020/</link>
      <pubDate>Fri, 27 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/mojtaba_tits2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;Action2Motion: Conditioned Generation of 3-D Human Motions&#34; is accepted by ACM Multimedia 2020</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/chuan_acmmm2020/</link>
      <pubDate>Sat, 25 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/chuan_acmmm2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Our paper &#34;3D Human Shape Reconstruction from a Polarization Image&#34; is accepted by ECCV 2020</title>
      <link>https://vision-and-learning-lab-ualberta.github.io/post/zou_eccv2020/</link>
      <pubDate>Sat, 04 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://vision-and-learning-lab-ualberta.github.io/post/zou_eccv2020/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
